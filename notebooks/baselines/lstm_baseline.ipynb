{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySY7VmYN2GjC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import nltk\n",
        "from nltk import WhitespaceTokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load preprocessed data\n"
      ],
      "metadata": {
        "id": "Y-LKpj3b6zVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tweets(file_path):\n",
        "    tweets = list()\n",
        "    with open(file_path, 'r', encoding='utf-8') as preprocessed_tweets:\n",
        "        for tweet in preprocessed_tweets :\n",
        "            tweets.append(tweet.rstrip('\\n'))\n",
        "    return tweets"
      ],
      "metadata": {
        "id": "P7BrjuLP61oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    train_pos_tweets = load_tweets('/content/processed_pos_tweets_non_transformer.txt')\n",
        "    train_neg_tweets = load_tweets('/content/processed_neg_tweets_non_transformer.txt')\n",
        "    test_tweets = load_tweets('/content/processed_test_tweets_non_transformer.txt')\n",
        "    print(\"Tweets loaded\")"
      ],
      "metadata": {
        "id": "JZUt9_5663fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1d8047-7b87-4811-b19a-513af4587d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweets loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to Dataframe"
      ],
      "metadata": {
        "id": "fZMn7jrB7vjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.utils import shuffle\n",
        "    seed =12222\n",
        "    train_neg_labels = [0] * len(train_neg_tweets)\n",
        "    train_pos_labels = [1] * len(train_pos_tweets)\n",
        "\n",
        "    train_tweets = train_pos_tweets + train_neg_tweets\n",
        "    train_labels = train_pos_labels + train_neg_labels\n",
        "    #Shuffle\n",
        "    train_tweets, train_labels = shuffle(train_tweets, train_labels, random_state=10)\n",
        "    data = pd.DataFrame({'tweet': train_tweets, 'label': train_labels})\n",
        "\n",
        "    X = list(data[\"tweet\"])\n",
        "    y = list(data[\"label\"])\n",
        "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05,stratify=y,random_state=seed)\n",
        "    # X_train_set = pd.DataFrame({'tweet': X_train, 'label': y_train})\n",
        "    # X_val_set = pd.DataFrame({'tweet': X_val, 'label': y_val})\n",
        "\n",
        "    # X_test_set = pd.DataFrame({'tweet': test_tweets})\n"
      ],
      "metadata": {
        "id": "DF7Dh0dW7yEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "7nFZO1zEsUGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "#Load Data\n",
        "tweets = np.array(X)\n",
        "labels = np.array(y)\n",
        "X_train_set = pd.DataFrame(columns = ['tweet', 'label'], data=np.array([tweets, labels]).T)\n",
        "#Tokenize tweets and pad\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(X_train_set['tweet'].values)\n",
        "X = tokenizer.texts_to_sequences(X_train_set['tweet'].values)\n",
        "X = pad_sequences(X, maxlen = 100)\n",
        "\n",
        "#Define Model\n",
        "embed_dim = 500 #400\n",
        "max_feat = 15000 #10000\n",
        "\n",
        "#Define Bidirectional LSTM layer\n",
        "LSTMLayer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200, dropout=0.3, recurrent_dropout=0.25))\n",
        "\n",
        "#Simple LSTM model (Noticed that the stacked one would perform worse)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_feat, embed_dim, input_length = X.shape[1]))\n",
        "\n",
        "model.add(SpatialDropout1D(0.35))\n",
        "\n",
        "model.add(LSTMLayer)\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "#Create Validation set\n",
        "Y = pd.get_dummies(X_train_set['label']).values\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.05, random_state = seed)\n",
        "\n",
        "#Train Model\n",
        "batch_size = 128\n",
        "history = model.fit(X_train, Y_train,  validation_data = [X_val, Y_val], epochs = 25,\n",
        "                    steps_per_epoch = 300, batch_size = batch_size, verbose = 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR-got_asUKO",
        "outputId": "cdff60e0-4cf4-4c03-b359-b85861b3af3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, 100, 500)          7500000   \n",
            "                                                                 \n",
            " spatial_dropout1d_20 (Spati  (None, 100, 500)         0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, 400)              1121600   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 2)                 802       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,622,402\n",
            "Trainable params: 8,622,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "300/300 [==============================] - 247s 803ms/step - loss: 0.5208 - accuracy: 0.7322 - val_loss: 0.4785 - val_accuracy: 0.7644\n",
            "Epoch 2/25\n",
            "300/300 [==============================] - 223s 743ms/step - loss: 0.4690 - accuracy: 0.7716 - val_loss: 0.4595 - val_accuracy: 0.7742\n",
            "Epoch 3/25\n",
            "300/300 [==============================] - 219s 729ms/step - loss: 0.4593 - accuracy: 0.7759 - val_loss: 0.4514 - val_accuracy: 0.7804\n",
            "Epoch 4/25\n",
            "300/300 [==============================] - 219s 731ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4444 - val_accuracy: 0.7867\n",
            "Epoch 5/25\n",
            "300/300 [==============================] - 219s 731ms/step - loss: 0.4403 - accuracy: 0.7864 - val_loss: 0.4404 - val_accuracy: 0.7872\n",
            "Epoch 6/25\n",
            "300/300 [==============================] - 219s 730ms/step - loss: 0.4395 - accuracy: 0.7864 - val_loss: 0.4329 - val_accuracy: 0.7909\n",
            "Epoch 7/25\n",
            "300/300 [==============================] - 219s 731ms/step - loss: 0.4348 - accuracy: 0.7886 - val_loss: 0.4306 - val_accuracy: 0.7920\n",
            "Epoch 8/25\n",
            "300/300 [==============================] - 219s 730ms/step - loss: 0.4359 - accuracy: 0.7896 - val_loss: 0.4298 - val_accuracy: 0.7939\n",
            "Epoch 9/25\n",
            "300/300 [==============================] - 218s 727ms/step - loss: 0.4313 - accuracy: 0.7948 - val_loss: 0.4287 - val_accuracy: 0.7941\n",
            "Epoch 10/25\n",
            "300/300 [==============================] - 218s 728ms/step - loss: 0.4266 - accuracy: 0.7952 - val_loss: 0.4317 - val_accuracy: 0.7949\n",
            "Epoch 11/25\n",
            "300/300 [==============================] - 218s 729ms/step - loss: 0.4306 - accuracy: 0.7893 - val_loss: 0.4225 - val_accuracy: 0.7970\n",
            "Epoch 12/25\n",
            "300/300 [==============================] - 219s 730ms/step - loss: 0.4238 - accuracy: 0.7955 - val_loss: 0.4224 - val_accuracy: 0.7984\n",
            "Epoch 13/25\n",
            "300/300 [==============================] - 221s 737ms/step - loss: 0.4267 - accuracy: 0.7963 - val_loss: 0.4203 - val_accuracy: 0.7993\n",
            "Epoch 14/25\n",
            "300/300 [==============================] - 220s 732ms/step - loss: 0.4232 - accuracy: 0.7983 - val_loss: 0.4203 - val_accuracy: 0.7984\n",
            "Epoch 15/25\n",
            "300/300 [==============================] - 220s 733ms/step - loss: 0.4236 - accuracy: 0.7956 - val_loss: 0.4185 - val_accuracy: 0.7998\n",
            "Epoch 16/25\n",
            "300/300 [==============================] - 220s 733ms/step - loss: 0.4199 - accuracy: 0.8006 - val_loss: 0.4184 - val_accuracy: 0.8005\n",
            "Epoch 17/25\n",
            "300/300 [==============================] - 218s 728ms/step - loss: 0.4182 - accuracy: 0.8041 - val_loss: 0.4181 - val_accuracy: 0.7995\n",
            "Epoch 18/25\n",
            "300/300 [==============================] - 218s 728ms/step - loss: 0.4174 - accuracy: 0.8001 - val_loss: 0.4232 - val_accuracy: 0.7992\n",
            "Epoch 19/25\n",
            "300/300 [==============================] - 217s 725ms/step - loss: 0.4138 - accuracy: 0.8034 - val_loss: 0.4180 - val_accuracy: 0.7994\n",
            "Epoch 20/25\n",
            "300/300 [==============================] - 219s 730ms/step - loss: 0.4179 - accuracy: 0.8027 - val_loss: 0.4173 - val_accuracy: 0.8006\n",
            "Epoch 21/25\n",
            "300/300 [==============================] - 218s 726ms/step - loss: 0.4204 - accuracy: 0.8007 - val_loss: 0.4180 - val_accuracy: 0.8002\n",
            "Epoch 22/25\n",
            "300/300 [==============================] - 220s 734ms/step - loss: 0.4180 - accuracy: 0.8016 - val_loss: 0.4137 - val_accuracy: 0.8015\n",
            "Epoch 23/25\n",
            "300/300 [==============================] - 219s 731ms/step - loss: 0.4145 - accuracy: 0.8015 - val_loss: 0.4151 - val_accuracy: 0.8027\n",
            "Epoch 24/25\n",
            "300/300 [==============================] - 218s 729ms/step - loss: 0.4136 - accuracy: 0.8029 - val_loss: 0.4143 - val_accuracy: 0.8021\n",
            "Epoch 25/25\n",
            "300/300 [==============================] - 217s 725ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.4115 - val_accuracy: 0.8041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_tweets\n",
        "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
        "X_test = pad_sequences(X_test, maxlen = 100)\n",
        "y_test = model.predict(X_val,batch_size=len(X_val))\n",
        "y_preds = [-1 if np.argmax(val) == 0 else 1 for val in y_test]\n",
        "df = pd.DataFrame(y_preds, columns=[\"Prediction\"])\n",
        "df.index.name = \"Id\"\n",
        "df.index += 1\n",
        "df.to_csv(\"/content/drive/MyDrive/test_data_word2vec_final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1JO5CsFUg72",
        "outputId": "d6de34df-6124-4f96-f0ec-9dfdf5792d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 585ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRqjeitIJAXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}